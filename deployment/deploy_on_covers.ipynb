{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying on a test set\n",
    "- Use model weights from various models (ResNet and CNN) to test on set of triplets of covers and random different songs\n",
    "- Try various triplet accuracy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from dotenv import dotenv_values \n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pickle as pkl\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, roc_auc_score, roc_curve\n",
    "from transformers import AutoProcessor, AutoModel, ASTModel, AutoFeatureExtractor, AutoModelForAudioClassification, Wav2Vec2Model\n",
    "\n",
    "import torch.optim as optim\n",
    "from pydub import AudioSegment\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pretrained resnet from Torch Vision resnet 18\n",
    "class ResNetEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim=128, dropout_rate=0.5):\n",
    "        # get resnet super class\n",
    "        super(ResNetEmbedding, self).__init__()\n",
    "        self.resnet = models.resnet18(weights='DEFAULT')\n",
    "        # Change structure of first layer to take non RGB images, rest of params same as default\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        # Set the last fully connected to a set dimension \"embedding_dim\" instead of default 1000\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        return F.normalize(x, p=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our other network\n",
    "class MusicSimilarityCNN(nn.Module):\n",
    "    def __init__(self, embedding_dim=128, dropout_rate=0.5):\n",
    "        super(MusicSimilarityCNN, self).__init__()\n",
    "        \n",
    "        # Layers to get to 128 dim embeddings\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1) \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1) \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1) \n",
    "        \n",
    "        # Batch norm for each \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Pooling\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        # FCs\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, embedding_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Add step to resize test set mel specs\n",
    "        x = torch.nn.functional.interpolate(x, size=(128, 128))\n",
    "        # CNN layers with ReLU activation and pooling - input [32, 1, 128,128]\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x)))) # Conv -> BatchNorm -> Relu -> Pool\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        # Flatten the output for the fully connected layer\n",
    "        x = x.view(-1, 128 * 8 * 8) # 128*8*8 = 8192 --> Shape = []\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        # Output the embeddings\n",
    "        x = self.fc2(x)\n",
    "        return F.normalize(x, p=2, dim=1)  # Normalize embeddings for better similarity comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioSpecTransformerModel(torch.nn.Module):\n",
    "    def __init__(self, pretrained_model_name=\"MIT/ast-finetuned-audioset-10-10-0.4593\", embedding_dim=128, dropout_rate=0.5):\n",
    "        super(AudioSpecTransformerModel, self).__init__()\n",
    "        \n",
    "        self.model = ASTModel.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.fc = torch.nn.Linear(self.model.config.hidden_size, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.model(x).last_hidden_state\n",
    "        \n",
    "        # Get [cls] token embedding for classification/summary of embedding\n",
    "        x = self.fc(outputs[:, 0, :])\n",
    "        \n",
    "        return F.normalize(x, p=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069e0c1990f74882bc5d1bbfbea3952e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d3cd43aa9e432796a900694caebe29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for AudioSpecTransformerModel:\n\tMissing key(s) in state_dict: \"model.embeddings.cls_token\", \"model.embeddings.distillation_token\", \"model.embeddings.position_embeddings\", \"model.embeddings.patch_embeddings.projection.weight\", \"model.embeddings.patch_embeddings.projection.bias\", \"model.encoder.layer.0.attention.attention.query.weight\", \"model.encoder.layer.0.attention.attention.query.bias\", \"model.encoder.layer.0.attention.attention.key.weight\", \"model.encoder.layer.0.attention.attention.key.bias\", \"model.encoder.layer.0.attention.attention.value.weight\", \"model.encoder.layer.0.attention.attention.value.bias\", \"model.encoder.layer.0.attention.output.dense.weight\", \"model.encoder.layer.0.attention.output.dense.bias\", \"model.encoder.layer.0.intermediate.dense.weight\", \"model.encoder.layer.0.intermediate.dense.bias\", \"model.encoder.layer.0.output.dense.weight\", \"model.encoder.layer.0.output.dense.bias\", \"model.encoder.layer.0.layernorm_before.weight\", \"model.encoder.layer.0.layernorm_before.bias\", \"model.encoder.layer.0.layernorm_after.weight\", \"model.encoder.layer.0.layernorm_after.bias\", \"model.encoder.layer.1.attention.attention.query.weight\", \"model.encoder.layer.1.attention.attention.query.bias\", \"model.encoder.layer.1.attention.attention.key.weight\", \"model.encoder.layer.1.attention.attention.key.bias\", \"model.encoder.layer.1.attention.attention.value.weight\", \"model.encoder.layer.1.attention.attention.value.bias\", \"model.encoder.layer.1.attention.output.dense.weight\", \"model.encoder.layer.1.attention.output.dense.bias\", \"model.encoder.layer.1.intermediate.dense.weight\", \"model.encoder.layer.1.intermediate.dense.bias\", \"model.encoder.layer.1.output.dense.weight\", \"model.encoder.layer.1.output.dense.bias\", \"model.encoder.layer.1.layernorm_before.weight\", \"model.encoder.layer.1.layernorm_before.bias\", \"model.encoder.layer.1.layernorm_after.weight\", \"model.encoder.layer.1.layernorm_after.bias\", \"model.encoder.layer.2.attention.attention.query.weight\", \"model.encoder.layer.2.attention.attention.query.bias\", \"model.encoder.layer.2.attention.attention.key.weight\", \"model.encoder.layer.2.attention.attention.key.bias\", \"model.encoder.layer.2.attention.attention.value.weight\", \"model.encoder.layer.2.attention.attention.value.bias\", \"model.encoder.layer.2.attention.output.dense.weight\", \"model.encoder.layer.2.attention.output.dense.bias\", \"model.encoder.layer.2.intermediate.dense.weight\", \"model.encoder.layer.2.intermediate.dense.bias\", \"model.encoder.layer.2.output.dense.weight\", \"model.encoder.layer.2.output.dense.bias\", \"model.encoder.layer.2.layernorm_before.weight\", \"model.encoder.layer.2.layernorm_before.bias\", \"model.encoder.layer.2.layernorm_after.weight\", \"model.encoder.layer.2.layernorm_after.bias\", \"model.encoder.layer.3.attention.attention.query.weight\", \"model.encoder.layer.3.attention.attention.query.bias\", \"model.encoder.layer.3.attention.attention.key.weight\", \"model.encoder.layer.3.attention.attention.key.bias\", \"model.encoder.layer.3.attention.attention.value.weight\", \"model.encoder.layer.3.attention.attention.value.bias\", \"model.encoder.layer.3.attention.output.dense.weight\", \"model.encoder.layer.3.attention.output.dense.bias\", \"model.encoder.layer.3.intermediate.dense.weight\", \"model.encoder.layer.3.intermediate.dense.bias\", \"model.encoder.layer.3.output.dense.weight\", \"model.encoder.layer.3.output.dense.bias\", \"model.encoder.layer.3.layernorm_before.weight\", \"model.encoder.layer.3.layernorm_before.bias\", \"model.encoder.layer.3.layernorm_after.weight\", \"model.encoder.layer.3.layernorm_after.bias\", \"model.encoder.layer.4.attention.attention.query.weight\", \"model.encoder.layer.4.attention.attention.query.bias\", \"model.encoder.layer.4.attention.attention.key.weight\", \"model.encoder.layer.4.attention.attention.key.bias\", \"model.encoder.layer.4.attention.attention.value.weight\", \"model.encoder.layer.4.attention.attention.value.bias\", \"model.encoder.layer.4.attention.output.dense.weight\", \"model.encoder.layer.4.attention.output.dense.bias\", \"model.encoder.layer.4.intermediate.dense.weight\", \"model.encoder.layer.4.intermediate.dense.bias\", \"model.encoder.layer.4.output.dense.weight\", \"model.encoder.layer.4.output.dense.bias\", \"model.encoder.layer.4.layernorm_before.weight\", \"model.encoder.layer.4.layernorm_before.bias\", \"model.encoder.layer.4.layernorm_after.weight\", \"model.encoder.layer.4.layernorm_after.bias\", \"model.encoder.layer.5.attention.attention.query.weight\", \"model.encoder.layer.5.attention.attention.query.bias\", \"model.encoder.layer.5.attention.attention.key.weight\", \"model.encoder.layer.5.attention.attention.key.bias\", \"model.encoder.layer.5.attention.attention.value.weight\", \"model.encoder.layer.5.attention.attention.value.bias\", \"model.encoder.layer.5.attention.output.dense.weight\", \"model.encoder.layer.5.attention.output.dense.bias\", \"model.encoder.layer.5.intermediate.dense.weight\", \"model.encoder.layer.5.intermediate.dense.bias\", \"model.encoder.layer.5.output.dense.weight\", \"model.encoder.layer.5.output.dense.bias\", \"model.encoder.layer.5.layernorm_before.weight\", \"model.encoder.layer.5.layernorm_before.bias\", \"model.encoder.layer.5.layernorm_after.weight\", \"model.encoder.layer.5.layernorm_after.bias\", \"model.encoder.layer.6.attention.attention.query.weight\", \"model.encoder.layer.6.attention.attention.query.bias\", \"model.encoder.layer.6.attention.attention.key.weight\", \"model.encoder.layer.6.attention.attention.key.bias\", \"model.encoder.layer.6.attention.attention.value.weight\", \"model.encoder.layer.6.attention.attention.value.bias\", \"model.encoder.layer.6.attention.output.dense.weight\", \"model.encoder.layer.6.attention.output.dense.bias\", \"model.encoder.layer.6.intermediate.dense.weight\", \"model.encoder.layer.6.intermediate.dense.bias\", \"model.encoder.layer.6.output.dense.weight\", \"model.encoder.layer.6.output.dense.bias\", \"model.encoder.layer.6.layernorm_before.weight\", \"model.encoder.layer.6.layernorm_before.bias\", \"model.encoder.layer.6.layernorm_after.weight\", \"model.encoder.layer.6.layernorm_after.bias\", \"model.encoder.layer.7.attention.attention.query.weight\", \"model.encoder.layer.7.attention.attention.query.bias\", \"model.encoder.layer.7.attention.attention.key.weight\", \"model.encoder.layer.7.attention.attention.key.bias\", \"model.encoder.layer.7.attention.attention.value.weight\", \"model.encoder.layer.7.attention.attention.value.bias\", \"model.encoder.layer.7.attention.output.dense.weight\", \"model.encoder.layer.7.attention.output.dense.bias\", \"model.encoder.layer.7.intermediate.dense.weight\", \"model.encoder.layer.7.intermediate.dense.bias\", \"model.encoder.layer.7.output.dense.weight\", \"model.encoder.layer.7.output.dense.bias\", \"model.encoder.layer.7.layernorm_before.weight\", \"model.encoder.layer.7.layernorm_before.bias\", \"model.encoder.layer.7.layernorm_after.weight\", \"model.encoder.layer.7.layernorm_after.bias\", \"model.encoder.layer.8.attention.attention.query.weight\", \"model.encoder.layer.8.attention.attention.query.bias\", \"model.encoder.layer.8.attention.attention.key.weight\", \"model.encoder.layer.8.attention.attention.key.bias\", \"model.encoder.layer.8.attention.attention.value.weight\", \"model.encoder.layer.8.attention.attention.value.bias\", \"model.encoder.layer.8.attention.output.dense.weight\", \"model.encoder.layer.8.attention.output.dense.bias\", \"model.encoder.layer.8.intermediate.dense.weight\", \"model.encoder.layer.8.intermediate.dense.bias\", \"model.encoder.layer.8.output.dense.weight\", \"model.encoder.layer.8.output.dense.bias\", \"model.encoder.layer.8.layernorm_before.weight\", \"model.encoder.layer.8.layernorm_before.bias\", \"model.encoder.layer.8.layernorm_after.weight\", \"model.encoder.layer.8.layernorm_after.bias\", \"model.encoder.layer.9.attention.attention.query.weight\", \"model.encoder.layer.9.attention.attention.query.bias\", \"model.encoder.layer.9.attention.attention.key.weight\", \"model.encoder.layer.9.attention.attention.key.bias\", \"model.encoder.layer.9.attention.attention.value.weight\", \"model.encoder.layer.9.attention.attention.value.bias\", \"model.encoder.layer.9.attention.output.dense.weight\", \"model.encoder.layer.9.attention.output.dense.bias\", \"model.encoder.layer.9.intermediate.dense.weight\", \"model.encoder.layer.9.intermediate.dense.bias\", \"model.encoder.layer.9.output.dense.weight\", \"model.encoder.layer.9.output.dense.bias\", \"model.encoder.layer.9.layernorm_before.weight\", \"model.encoder.layer.9.layernorm_before.bias\", \"model.encoder.layer.9.layernorm_after.weight\", \"model.encoder.layer.9.layernorm_after.bias\", \"model.encoder.layer.10.attention.attention.query.weight\", \"model.encoder.layer.10.attention.attention.query.bias\", \"model.encoder.layer.10.attention.attention.key.weight\", \"model.encoder.layer.10.attention.attention.key.bias\", \"model.encoder.layer.10.attention.attention.value.weight\", \"model.encoder.layer.10.attention.attention.value.bias\", \"model.encoder.layer.10.attention.output.dense.weight\", \"model.encoder.layer.10.attention.output.dense.bias\", \"model.encoder.layer.10.intermediate.dense.weight\", \"model.encoder.layer.10.intermediate.dense.bias\", \"model.encoder.layer.10.output.dense.weight\", \"model.encoder.layer.10.output.dense.bias\", \"model.encoder.layer.10.layernorm_before.weight\", \"model.encoder.layer.10.layernorm_before.bias\", \"model.encoder.layer.10.layernorm_after.weight\", \"model.encoder.layer.10.layernorm_after.bias\", \"model.encoder.layer.11.attention.attention.query.weight\", \"model.encoder.layer.11.attention.attention.query.bias\", \"model.encoder.layer.11.attention.attention.key.weight\", \"model.encoder.layer.11.attention.attention.key.bias\", \"model.encoder.layer.11.attention.attention.value.weight\", \"model.encoder.layer.11.attention.attention.value.bias\", \"model.encoder.layer.11.attention.output.dense.weight\", \"model.encoder.layer.11.attention.output.dense.bias\", \"model.encoder.layer.11.intermediate.dense.weight\", \"model.encoder.layer.11.intermediate.dense.bias\", \"model.encoder.layer.11.output.dense.weight\", \"model.encoder.layer.11.output.dense.bias\", \"model.encoder.layer.11.layernorm_before.weight\", \"model.encoder.layer.11.layernorm_before.bias\", \"model.encoder.layer.11.layernorm_after.weight\", \"model.encoder.layer.11.layernorm_after.bias\", \"model.layernorm.weight\", \"model.layernorm.bias\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"model_state_dict\", \"optimizer_state_dict\", \"epoch\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# How to load the model later using just the state dictionary\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#model = ResNetEmbedding()  # Make sure this matches the architecture you used\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#model.load_state_dict(torch.load('../modeling/resnet_output/resnet18_model_weights.pth', map_location=torch.device('cpu')))\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#model = MusicSimilarityCNN()\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#model.load_state_dict(torch.load('../modeling/cnn_output/cnn_model_weights.pth', map_location=torch.device('cpu')))\u001b[39;00m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m AudioSpecTransformerModel()\n\u001b[0;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../modeling/transformer_output/audio_spec_checkpoint.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# If using a GPU\u001b[39;00m\n\u001b[1;32m     12\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/erdos_may_2024/lib/python3.11/site-packages/torch/nn/modules/module.py:2189\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2184\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2185\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2186\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2190\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for AudioSpecTransformerModel:\n\tMissing key(s) in state_dict: \"model.embeddings.cls_token\", \"model.embeddings.distillation_token\", \"model.embeddings.position_embeddings\", \"model.embeddings.patch_embeddings.projection.weight\", \"model.embeddings.patch_embeddings.projection.bias\", \"model.encoder.layer.0.attention.attention.query.weight\", \"model.encoder.layer.0.attention.attention.query.bias\", \"model.encoder.layer.0.attention.attention.key.weight\", \"model.encoder.layer.0.attention.attention.key.bias\", \"model.encoder.layer.0.attention.attention.value.weight\", \"model.encoder.layer.0.attention.attention.value.bias\", \"model.encoder.layer.0.attention.output.dense.weight\", \"model.encoder.layer.0.attention.output.dense.bias\", \"model.encoder.layer.0.intermediate.dense.weight\", \"model.encoder.layer.0.intermediate.dense.bias\", \"model.encoder.layer.0.output.dense.weight\", \"model.encoder.layer.0.output.dense.bias\", \"model.encoder.layer.0.layernorm_before.weight\", \"model.encoder.layer.0.layernorm_before.bias\", \"model.encoder.layer.0.layernorm_after.weight\", \"model.encoder.layer.0.layernorm_after.bias\", \"model.encoder.layer.1.attention.attention.query.weight\", \"model.encoder.layer.1.attention.attention.query.bias\", \"model.encoder.layer.1.attention.attention.key.weight\", \"model.encoder.layer.1.attention.attention.key.bias\", \"model.encoder.layer.1.attention.attention.value.weight\", \"model.encoder.layer.1.attention.attention.value.bias\", \"model.encoder.layer.1.attention.output.dense.weight\", \"model.encoder.layer.1.attention.output.dense.bias\", \"model.encoder.layer.1.intermediate.dense.weight\", \"model.encoder.layer.1.intermediate.dense.bias\", \"model.encoder.layer.1.output.dense.weight\", \"model.encoder.layer.1.output.dense.bias\", \"model.encoder.layer.1.layernorm_before.weight\", \"model.encoder.layer.1.layernorm_before.bias\", \"model.encoder.layer.1.layernorm_after.weight\", \"model.encoder.layer.1.layernorm_after.bias\", \"model.encoder.layer.2.attention.attention.query.weight\", \"model.encoder.layer.2.attention.attention.query.bias\", \"model.encoder.layer.2.attention.attention.key.weight\", \"model.encoder.layer.2.attention.attention.key.bias\", \"model.encoder.layer.2.attention.attention.value.weight\", \"model.encoder.layer.2.attention.attention.value.bias\", \"model.encoder.layer.2.attention.output.dense.weight\", \"model.encoder.layer.2.attention.output.dense.bias\", \"model.encoder.layer.2.intermediate.dense.weight\", \"model.encoder.layer.2.intermediate.dense.bias\", \"model.encoder.layer.2.output.dense.weight\", \"model.encoder.layer.2.output.dense.bias\", \"model.encoder.layer.2.layernorm_before.weight\", \"model.encoder.layer.2.layernorm_before.bias\", \"model.encoder.layer.2.layernorm_after.weight\", \"model.encoder.layer.2.layernorm_after.bias\", \"model.encoder.layer.3.attention.attention.query.weight\", \"model.encoder.layer.3.attention.attention.query.bias\", \"model.encoder.layer.3.attention.attention.key.weight\", \"model.encoder.layer.3.attention.attention.key.bias\", \"model.encoder.layer.3.attention.attention.value.weight\", \"model.encoder.layer.3.attention.attention.value.bias\", \"model.encoder.layer.3.attention.output.dense.weight\", \"model.encoder.layer.3.attention.output.dense.bias\", \"model.encoder.layer.3.intermediate.dense.weight\", \"model.encoder.layer.3.intermediate.dense.bias\", \"model.encoder.layer.3.output.dense.weight\", \"model.encoder.layer.3.output.dense.bias\", \"model.encoder.layer.3.layernorm_before.weight\", \"model.encoder.layer.3.layernorm_before.bias\", \"model.encoder.layer.3.layernorm_after.weight\", \"model.encoder.layer.3.layernorm_after.bias\", \"model.encoder.layer.4.attention.attention.query.weight\", \"model.encoder.layer.4.attention.attention.query.bias\", \"model.encoder.layer.4.attention.attention.key.weight\", \"model.encoder.layer.4.attention.attention.key.bias\", \"model.encoder.layer.4.attention.attention.value.weight\", \"model.encoder.layer.4.attention.attention.value.bias\", \"model.encoder.layer.4.attention.output.dense.weight\", \"model.encoder.layer.4.attention.output.dense.bias\", \"model.encoder.layer.4.intermediate.dense.weight\", \"model.encoder.layer.4.intermediate.dense.bias\", \"model.encoder.layer.4.output.dense.weight\", \"model.encoder.layer.4.output.dense.bias\", \"model.encoder.layer.4.layernorm_before.weight\", \"model.encoder.layer.4.layernorm_before.bias\", \"model.encoder.layer.4.layernorm_after.weight\", \"model.encoder.layer.4.layernorm_after.bias\", \"model.encoder.layer.5.attention.attention.query.weight\", \"model.encoder.layer.5.attention.attention.query.bias\", \"model.encoder.layer.5.attention.attention.key.weight\", \"model.encoder.layer.5.attention.attention.key.bias\", \"model.encoder.layer.5.attention.attention.value.weight\", \"model.encoder.layer.5.attention.attention.value.bias\", \"model.encoder.layer.5.attention.output.dense.weight\", \"model.encoder.layer.5.attention.output.dense.bias\", \"model.encoder.layer.5.intermediate.dense.weight\", \"model.encoder.layer.5.intermediate.dense.bias\", \"model.encoder.layer.5.output.dense.weight\", \"model.encoder.layer.5.output.dense.bias\", \"model.encoder.layer.5.layernorm_before.weight\", \"model.encoder.layer.5.layernorm_before.bias\", \"model.encoder.layer.5.layernorm_after.weight\", \"model.encoder.layer.5.layernorm_after.bias\", \"model.encoder.layer.6.attention.attention.query.weight\", \"model.encoder.layer.6.attention.attention.query.bias\", \"model.encoder.layer.6.attention.attention.key.weight\", \"model.encoder.layer.6.attention.attention.key.bias\", \"model.encoder.layer.6.attention.attention.value.weight\", \"model.encoder.layer.6.attention.attention.value.bias\", \"model.encoder.layer.6.attention.output.dense.weight\", \"model.encoder.layer.6.attention.output.dense.bias\", \"model.encoder.layer.6.intermediate.dense.weight\", \"model.encoder.layer.6.intermediate.dense.bias\", \"model.encoder.layer.6.output.dense.weight\", \"model.encoder.layer.6.output.dense.bias\", \"model.encoder.layer.6.layernorm_before.weight\", \"model.encoder.layer.6.layernorm_before.bias\", \"model.encoder.layer.6.layernorm_after.weight\", \"model.encoder.layer.6.layernorm_after.bias\", \"model.encoder.layer.7.attention.attention.query.weight\", \"model.encoder.layer.7.attention.attention.query.bias\", \"model.encoder.layer.7.attention.attention.key.weight\", \"model.encoder.layer.7.attention.attention.key.bias\", \"model.encoder.layer.7.attention.attention.value.weight\", \"model.encoder.layer.7.attention.attention.value.bias\", \"model.encoder.layer.7.attention.output.dense.weight\", \"model.encoder.layer.7.attention.output.dense.bias\", \"model.encoder.layer.7.intermediate.dense.weight\", \"model.encoder.layer.7.intermediate.dense.bias\", \"model.encoder.layer.7.output.dense.weight\", \"model.encoder.layer.7.output.dense.bias\", \"model.encoder.layer.7.layernorm_before.weight\", \"model.encoder.layer.7.layernorm_before.bias\", \"model.encoder.layer.7.layernorm_after.weight\", \"model.encoder.layer.7.layernorm_after.bias\", \"model.encoder.layer.8.attention.attention.query.weight\", \"model.encoder.layer.8.attention.attention.query.bias\", \"model.encoder.layer.8.attention.attention.key.weight\", \"model.encoder.layer.8.attention.attention.key.bias\", \"model.encoder.layer.8.attention.attention.value.weight\", \"model.encoder.layer.8.attention.attention.value.bias\", \"model.encoder.layer.8.attention.output.dense.weight\", \"model.encoder.layer.8.attention.output.dense.bias\", \"model.encoder.layer.8.intermediate.dense.weight\", \"model.encoder.layer.8.intermediate.dense.bias\", \"model.encoder.layer.8.output.dense.weight\", \"model.encoder.layer.8.output.dense.bias\", \"model.encoder.layer.8.layernorm_before.weight\", \"model.encoder.layer.8.layernorm_before.bias\", \"model.encoder.layer.8.layernorm_after.weight\", \"model.encoder.layer.8.layernorm_after.bias\", \"model.encoder.layer.9.attention.attention.query.weight\", \"model.encoder.layer.9.attention.attention.query.bias\", \"model.encoder.layer.9.attention.attention.key.weight\", \"model.encoder.layer.9.attention.attention.key.bias\", \"model.encoder.layer.9.attention.attention.value.weight\", \"model.encoder.layer.9.attention.attention.value.bias\", \"model.encoder.layer.9.attention.output.dense.weight\", \"model.encoder.layer.9.attention.output.dense.bias\", \"model.encoder.layer.9.intermediate.dense.weight\", \"model.encoder.layer.9.intermediate.dense.bias\", \"model.encoder.layer.9.output.dense.weight\", \"model.encoder.layer.9.output.dense.bias\", \"model.encoder.layer.9.layernorm_before.weight\", \"model.encoder.layer.9.layernorm_before.bias\", \"model.encoder.layer.9.layernorm_after.weight\", \"model.encoder.layer.9.layernorm_after.bias\", \"model.encoder.layer.10.attention.attention.query.weight\", \"model.encoder.layer.10.attention.attention.query.bias\", \"model.encoder.layer.10.attention.attention.key.weight\", \"model.encoder.layer.10.attention.attention.key.bias\", \"model.encoder.layer.10.attention.attention.value.weight\", \"model.encoder.layer.10.attention.attention.value.bias\", \"model.encoder.layer.10.attention.output.dense.weight\", \"model.encoder.layer.10.attention.output.dense.bias\", \"model.encoder.layer.10.intermediate.dense.weight\", \"model.encoder.layer.10.intermediate.dense.bias\", \"model.encoder.layer.10.output.dense.weight\", \"model.encoder.layer.10.output.dense.bias\", \"model.encoder.layer.10.layernorm_before.weight\", \"model.encoder.layer.10.layernorm_before.bias\", \"model.encoder.layer.10.layernorm_after.weight\", \"model.encoder.layer.10.layernorm_after.bias\", \"model.encoder.layer.11.attention.attention.query.weight\", \"model.encoder.layer.11.attention.attention.query.bias\", \"model.encoder.layer.11.attention.attention.key.weight\", \"model.encoder.layer.11.attention.attention.key.bias\", \"model.encoder.layer.11.attention.attention.value.weight\", \"model.encoder.layer.11.attention.attention.value.bias\", \"model.encoder.layer.11.attention.output.dense.weight\", \"model.encoder.layer.11.attention.output.dense.bias\", \"model.encoder.layer.11.intermediate.dense.weight\", \"model.encoder.layer.11.intermediate.dense.bias\", \"model.encoder.layer.11.output.dense.weight\", \"model.encoder.layer.11.output.dense.bias\", \"model.encoder.layer.11.layernorm_before.weight\", \"model.encoder.layer.11.layernorm_before.bias\", \"model.encoder.layer.11.layernorm_after.weight\", \"model.encoder.layer.11.layernorm_after.bias\", \"model.layernorm.weight\", \"model.layernorm.bias\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"model_state_dict\", \"optimizer_state_dict\", \"epoch\". "
     ]
    }
   ],
   "source": [
    "# How to load the model later using just the state dictionary\n",
    "#model = ResNetEmbedding()  # Make sure this matches the architecture you used\n",
    "#model.load_state_dict(torch.load('../modeling/resnet_output/resnet18_model_weights.pth', map_location=torch.device('cpu')))\n",
    "\n",
    "#model = MusicSimilarityCNN()\n",
    "#model.load_state_dict(torch.load('../modeling/cnn_output/cnn_model_weights.pth', map_location=torch.device('cpu')))\n",
    "\n",
    "model = AudioSpecTransformerModel()\n",
    "model.load_state_dict(torch.load('../modeling/transformer_output/audio_spec_checkpoint.pth', map_location=torch.device('cpu')))\n",
    "\n",
    "# If using a GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance(model, row, use_model=True):\n",
    "    song_1 = row['song_1']\n",
    "    song_2 = row['song_2']\n",
    "    \n",
    "    # Assuming the input for deployment is already a mel spec y values\n",
    "    mel_tensor_1 = torch.tensor(song_1, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "    mel_tensor_2 = torch.tensor(song_2, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "    # Get with model\n",
    "    if use_model:\n",
    "        # Get the embedding from the model. No need to normalize, since forward pass does that\n",
    "        with torch.no_grad():\n",
    "            embedding_1 = model(mel_tensor_1)\n",
    "            embedding_2 = model(mel_tensor_2)\n",
    "\n",
    "    else:\n",
    "        # Flatten to get rid of dimensions, then unqueeze to make 2D with batch dimension \n",
    "        no_model_embedding_1 = F.normalize(mel_tensor_1.flatten().unsqueeze(0), p=2, dim=1)\n",
    "        no_model_embedding_2 = F.normalize(mel_tensor_2.flatten().unsqueeze(0), p=2, dim=1)\n",
    "\n",
    "    euclidean_distance = torch.dist(embedding_1, embedding_2).item()\n",
    "    #cosine_similarity = F.cosine_similarity(embedding_1, embedding_2).item()\n",
    "    return euclidean_distance\n",
    "\n",
    "def get_label(row, threshold=0.5):\n",
    "    if row['euclidean_distance'] > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_title_1</th>\n",
       "      <th>artist_1</th>\n",
       "      <th>album_1</th>\n",
       "      <th>song_1</th>\n",
       "      <th>song_title_2</th>\n",
       "      <th>artist_2</th>\n",
       "      <th>album_2</th>\n",
       "      <th>song_2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Claudette</td>\n",
       "      <td>everly_brothers</td>\n",
       "      <td>The_Fabulous_Style_of</td>\n",
       "      <td>[[-49.7658, -50.9627, -44.81154, -38.146698, -...</td>\n",
       "      <td>Claudette</td>\n",
       "      <td>everly_brothers</td>\n",
       "      <td>The_Fabulous_Style_of</td>\n",
       "      <td>[[-26.068644, -23.991093, -23.518074, -26.1214...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Claudette</td>\n",
       "      <td>everly_brothers</td>\n",
       "      <td>The_Fabulous_Style_of</td>\n",
       "      <td>[[-49.7658, -50.9627, -44.81154, -38.146698, -...</td>\n",
       "      <td>12-Day_Tripper</td>\n",
       "      <td>/Users/reggiebain/erdos/song-similarity-erdos/...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-39.67006, -36.35625, -30.621237, -25.635677...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  song_title_1         artist_1                album_1  \\\n",
       "0    Claudette  everly_brothers  The_Fabulous_Style_of   \n",
       "1    Claudette  everly_brothers  The_Fabulous_Style_of   \n",
       "\n",
       "                                              song_1    song_title_2  \\\n",
       "0  [[-49.7658, -50.9627, -44.81154, -38.146698, -...       Claudette   \n",
       "1  [[-49.7658, -50.9627, -44.81154, -38.146698, -...  12-Day_Tripper   \n",
       "\n",
       "                                            artist_2                album_2  \\\n",
       "0                                    everly_brothers  The_Fabulous_Style_of   \n",
       "1  /Users/reggiebain/erdos/song-similarity-erdos/...                      1   \n",
       "\n",
       "                                              song_2  label  \n",
       "0  [[-26.068644, -23.991093, -23.518074, -26.1214...      1  \n",
       "1  [[-39.67006, -36.35625, -30.621237, -25.635677...      0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataframe we made for deployment\n",
    "deploy_df = pd.read_pickle('../data/paired_songs_spectrograms_test.pkl')\n",
    "deploy_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Distances...: 100%|██████████| 154/154 [00:05<00:00, 27.98it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas(desc=f\"Computing Distances...\")\n",
    "deploy_df['euclidean_distance'] = deploy_df.progress_apply(lambda row: compute_distance(model, row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Distance of Covers: 0.6915950473252829\n",
      "Mean Distance of NOT Covers: 0.7203660433168535\n"
     ]
    }
   ],
   "source": [
    "# Compare means of means based on label\n",
    "print(f\"Mean Distance of Covers: {deploy_df[deploy_df.label == 1].euclidean_distance.mean()}\")\n",
    "print(f\"Mean Distance of NOT Covers: {deploy_df[deploy_df.label == 0].euclidean_distance.mean()}\")\n",
    "#print(f\"Mean Sim of Covers: {deploy_df[deploy_df.label == 1].cosine_similarity.mean()}\")\n",
    "#print(f\"Mean Sim of NOT Covers: {deploy_df[deploy_df.label == 0].cosine_similarity.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas(desc=f\"Getting Labels using mean threshold...\")\n",
    "deploy_df['deploy_label'] = deploy_df.apply(lambda row: get_label(row, threshold=deploy_df['euclidean_distance'].mean()), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(8,4))\n",
    "sns.histplot(data=deploy_df, x='euclidean_distance', hue='label', ax=axes[0])\n",
    "sns.histplot(data=deploy_df, x='euclidean_distance', hue='deploy_label', ax=axes[1])\n",
    "axes[0].legend(title='True Labels', labels=['Not Cover', 'Cover'])\n",
    "axes[1].legend(title='Model Labels', labels=['Not Cover', 'Cover'])\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/distances_by_label_transformers.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4481\n",
      "Precision: 0.4375\n",
      "F1 Score: 0.3972\n",
      "Recall: 0.36363636363636365\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy, precision, recall, F1\n",
    "accuracy = accuracy_score(deploy_df['label'], deploy_df['deploy_label'])\n",
    "precision = precision_score(deploy_df['label'], deploy_df['deploy_label'])\n",
    "f1 = f1_score(deploy_df['label'], deploy_df['deploy_label'])\n",
    "recall = recall_score(deploy_df['label'], deploy_df['deploy_label'])\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "print(f\"Recall: {recall}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Nearest Neighbor Accuracy and other Triplet Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_title</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>song</th>\n",
       "      <th>anchors</th>\n",
       "      <th>positives</th>\n",
       "      <th>negatives</th>\n",
       "      <th>neg_song</th>\n",
       "      <th>neg_artist</th>\n",
       "      <th>neg_album</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Claudette</td>\n",
       "      <td>everly_brothers</td>\n",
       "      <td>The_Fabulous_Style_of</td>\n",
       "      <td>01-Claudette</td>\n",
       "      <td>[[-80.0, -80.0, -80.0, -80.0, -80.0, -80.0, -8...</td>\n",
       "      <td>[[-80.0, -80.0, -80.0, -61.775627, -48.010227,...</td>\n",
       "      <td>[[-80.0, -80.0, -80.0, -80.0, -76.417206, -74....</td>\n",
       "      <td>03-Addicted_To_Love</td>\n",
       "      <td>/Users/reggiebain/erdos/song-similarity-erdos/...</td>\n",
       "      <td>Riptide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I_Don_t_Want_To_Miss_A_Thing</td>\n",
       "      <td>aerosmith</td>\n",
       "      <td>Armageddon_Original_Soundtrack_</td>\n",
       "      <td>01-I_Don_t_Want_To_Miss_A_Thing</td>\n",
       "      <td>[[-80.0, -80.0, -80.0, -79.25159, -56.510735, ...</td>\n",
       "      <td>[[-80.0, -80.0, -80.0, -80.0, -80.0, -80.0, -8...</td>\n",
       "      <td>[[-80.0, -80.0, -80.0, -80.0, -80.0, -80.0, -8...</td>\n",
       "      <td>09-Summertime_Blues</td>\n",
       "      <td>/Users/reggiebain/erdos/song-similarity-erdos/...</td>\n",
       "      <td>Surfin_USA_Surfin_Safari</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     song_title           artist  \\\n",
       "0                     Claudette  everly_brothers   \n",
       "1  I_Don_t_Want_To_Miss_A_Thing        aerosmith   \n",
       "\n",
       "                             album                             song  \\\n",
       "0            The_Fabulous_Style_of                     01-Claudette   \n",
       "1  Armageddon_Original_Soundtrack_  01-I_Don_t_Want_To_Miss_A_Thing   \n",
       "\n",
       "                                             anchors  \\\n",
       "0  [[-80.0, -80.0, -80.0, -80.0, -80.0, -80.0, -8...   \n",
       "1  [[-80.0, -80.0, -80.0, -79.25159, -56.510735, ...   \n",
       "\n",
       "                                           positives  \\\n",
       "0  [[-80.0, -80.0, -80.0, -61.775627, -48.010227,...   \n",
       "1  [[-80.0, -80.0, -80.0, -80.0, -80.0, -80.0, -8...   \n",
       "\n",
       "                                           negatives             neg_song  \\\n",
       "0  [[-80.0, -80.0, -80.0, -80.0, -76.417206, -74....  03-Addicted_To_Love   \n",
       "1  [[-80.0, -80.0, -80.0, -80.0, -80.0, -80.0, -8...  09-Summertime_Blues   \n",
       "\n",
       "                                          neg_artist                 neg_album  \n",
       "0  /Users/reggiebain/erdos/song-similarity-erdos/...                   Riptide  \n",
       "1  /Users/reggiebain/erdos/song-similarity-erdos/...  Surfin_USA_Surfin_Safari  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the original test files with triplets\n",
    "triplet_df = pd.read_pickle('/Users/reggiebain/erdos/song-similarity-erdos/data/test_set_covers.pkl')\n",
    "triplet_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find if positive or negative sample is closer. 1 if pos closer 0 if not.\n",
    "def find_closer_neighbor(row):\n",
    "    anchor, positive, negative = row['anchors'], row['positives'], row['negatives']\n",
    "\n",
    "    # Assuming the input for deployment is already a mel spec y values\n",
    "    anchor_tensor = torch.tensor(anchor, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "    positive_tensor = torch.tensor(positive, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "    negative_tensor = torch.tensor(negative, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        anchor_embedding = model(anchor_tensor)\n",
    "        positive_embedding = model(positive_tensor)\n",
    "        negative_embedding = model(negative_tensor)\n",
    "\n",
    "    anchor_positive_dist = torch.dist(anchor_embedding, positive_embedding).item()\n",
    "    anchor_negative_dist = torch.dist(anchor_embedding, negative_embedding).item()\n",
    "    #cosine_similarity = F.cosine_similarity(embedding_1, embedding_2).item()\n",
    "    \n",
    "    closer_neighbor = 1 if anchor_positive_dist > anchor_negative_dist else 0\n",
    "    return closer_neighbor\n",
    "\n",
    "# Calculate the accuracy given a column\n",
    "def get_nn_accuracy(df):\n",
    "    return df['closer_neighbor'].mean()    \n",
    "\n",
    "# Calculate baseline accuracy by randomly guessing\n",
    "def get_baseline_nn_accuracy(df):\n",
    "    random_guesses = np.random.choice([0, 1], size=len(df))\n",
    "    baseline_accuracy = (df['closer_neighbor'] == random_guesses).mean()\n",
    "    return baseline_accuracy\n",
    "\n",
    "def get_pct_improve(nn, baseline):\n",
    "    return (nn - baseline)/baseline * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating triplet inner products...:   0%|          | 0/77 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating triplet inner products...: 100%|██████████| 77/77 [00:06<00:00, 12.01it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas(desc=f\"Calculating triplet inner products...\")\n",
    "triplet_df['closer_neighbor'] = triplet_df.progress_apply(lambda row: find_closer_neighbor(row), axis=1)\n",
    "nn_accuracy = get_nn_accuracy(triplet_df)\n",
    "baseline_accuracy = get_baseline_nn_accuracy(triplet_df)\n",
    "pct_improve = get_pct_improve(nn_accuracy, baseline_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbor Accuracy: 36.3636%\n",
      "Baseline Accuracy: 40.2597%\n",
      "Model % Improvement: -9.6774%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nearest Neighbor Accuracy: {nn_accuracy*100:.4f}%\")\n",
    "print(f\"Baseline Accuracy: {baseline_accuracy*100:.4f}%\")\n",
    "print(f\"Model % Improvement: {pct_improve:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Spotify for Track to Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stuff from .env file\n",
    "env_vars = dotenv_values('.env')\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(\n",
    "    client_id=os.getenv(\"SPOTIFY_CLIENT_ID\"),\n",
    "    client_secret=os.getenv(\"SPOTIFY_CLIENT_SECRET\"),\n",
    ")\n",
    "# Get Spotify api client and apply to df\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the preview URL of a song based on artist name and song title\n",
    "#@retry(wait=wait_exponential(multiplier=1, min=4, max=60), stop=stop_after_attempt(10))\n",
    "def search_track(artist_name, track_name, sp, rate_limit = 1.0):\n",
    "    # Search for the track\n",
    "    result = sp.search(q=f'artist:{artist_name} track:{track_name}', type='track', limit=1)\n",
    "    if result['tracks']['items']:\n",
    "        # Return the preview URL if found\n",
    "        return result['tracks']['items'][0]['preview_url']\n",
    "    print('Arist/Track not found...')\n",
    "    return None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track1_name = 'Under Pressure'\n",
    "track1_artist = 'Bowie'\n",
    "track2_name = 'Rosanna'\n",
    "track2_artist = 'Toto'\n",
    "track1 = search_track(track1_artist, track1_name, sp)\n",
    "track2 = search_track(track1_artist, track1_name, sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_name = 'Robin Thicke'\n",
    "track_name = 'Surfin USA'\n",
    "#result = sp.search(q=f'artist:{artist_name} track:{track_name}', type='track', limit=1)\n",
    "result = sp.search(q=f'track:{track_name}', type='track', limit=1)\n",
    "preview = None\n",
    "for item in result['tracks']['items']:\n",
    "    if item['preview_url'] is not None:\n",
    "        preview = item['preview_url']\n",
    "        break\n",
    "preview   \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_may_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
